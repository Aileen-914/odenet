{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst müssen einige Module importiert werden, die wir nutzen wollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import random\n",
    "from random import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt machen wir die OdeNet-XML-Datei auf, parsen das XML und öffnen eine Datei, in die die Ausgabe geschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_wn = open(r\"C:\\Users\\melaniesiegel\\Documents\\05_Projekte\\WordNet\\OdeNet\\odenet.git\\trunk\\deWordNet.xml\",\"r\",encoding=\"utf-8\")\n",
    "\n",
    "out_lex = open(\"out_lex.txt\",\"w\",encoding=\"utf-8\")\n",
    "\n",
    "tree = ET.parse(de_wn)\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "lexicon = root.find('Lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_lemma greift man auf Lexikon-Einträge zu, bekommt die Lexikon-ID für ein Wort, den Lemma-Wert, POS und die IDs der Synsets, in denen das Wort enthalten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_lemma(word_to_check):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        lemma = lexentry.find('Lemma')\n",
    "        lemma_value = lemma.attrib['writtenForm']\n",
    "        lemma_id = lexentry.attrib['id']\n",
    "        if lemma_value == word_to_check:\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append([sense_id,synset_id])\n",
    "#            print(\"LEMMA: \" + lemma_value + \"\\nPOS: \" + pos + \"\\nSENSE ID: \" + sense_id)\n",
    "            return(lemma_id, lemma_value, pos, senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('w44207', 'Weihnachten', 'n', [['w44207_11098-n', 'odenet-11098-n']])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_lemma(\"Weihnachten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier bekommt man die Lexikon-IDs für eine Liste von Wörtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2ids(wordlist):\n",
    "    word_id_list = []\n",
    "    for word in wordlist:\n",
    "        try:\n",
    "            lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "            word_id_list.append(lemma_id)\n",
    "        except:\n",
    "            print(word + \" NOT IN ODENET\")\n",
    "    return(word_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w14145', 'w44811', 'w1202374', 'w25612']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2ids(['Frühling','Sommer','Herbst','Winter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_id bekommt man für eine Lexikon-ID Lemma, POS, Synsets und Relationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_id(id):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        if lexentry.attrib['id'] == id:\n",
    "            lemma = lexentry.find('Lemma')\n",
    "            lemma_value = lemma.attrib['writtenForm']\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append(synset_id)\n",
    "                relations = []\n",
    "                if sense.find('SenseRelation') != None:\n",
    "                    for relation in sense.iter('SenseRelation'):\n",
    "                        reltype = relation.attrib['relType']\n",
    "                        reltarget = relation.attrib['target']\n",
    "                        relations.append((reltype,reltarget))\n",
    "    return(lemma_value, pos, senses,relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Frühling', 'n', ['odenet-3067-n'], [])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_id('w14145')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit words_in_synset bekommt man die Wörter, die in einem Synset sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_synset(id):\n",
    "    words = []\n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        for sense in lexentry.iter('Sense'):\n",
    "            if sense.attrib['synset'] == id:\n",
    "                lemma = lexentry.find('Lemma').attrib['writtenForm']\n",
    "                words.append(lemma)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monitoring', 'Beaufsichtigung', 'Überwachung', 'Aufsicht']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_synset('odenet-2754-n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_synset bekommt man alle Informationen zu einem Synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_synset(id):\n",
    "    words = words_in_synset(id)\n",
    "    for synset in lexicon.iter('Synset'):\n",
    "        if id == synset.attrib['id']:\n",
    "            ili = synset.attrib['ili']\n",
    "            try:\n",
    "                en_definition = synset.attrib[\"{http://purl.org/dc/elements/1.1/}description\"]\n",
    "            except KeyError:\n",
    "                en_definition = []\n",
    "            if synset.find('Definition') != None:\n",
    "                de_definition = synset.find('Definition').text.strip()\n",
    "            else:\n",
    "                de_definition = []\n",
    "            relations = []\n",
    "            for relation in synset.iter('SynsetRelation'):\n",
    "                reltype = relation.attrib['relType']\n",
    "                reltarget = relation.attrib['target']\n",
    "                relations.append((reltype,reltarget))\n",
    "            return(ili,en_definition,de_definition, relations, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i26388',\n",
       " 'to say, state, or perform again',\n",
       " [],\n",
       " [('hyponym', 'odenet-5119-v'),\n",
       "  ('hyponym', 'odenet-423-a'),\n",
       "  ('hyponym', 'odenet-34404-v'),\n",
       "  ('hyponym', 'odenet-10538-v'),\n",
       "  ('hyponym', 'odenet-11423-v'),\n",
       "  ('hyponym', 'odenet-15312-n'),\n",
       "  ('hyponym', 'odenet-17105-v'),\n",
       "  ('hyponym', 'odenet-263-v')],\n",
       " ['wiederholt', 'mehrfach', 'mehrmalig', 'x-malig', '...malig'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_synset(\"odenet-25555-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypernyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hypernym\":\n",
    "                hypernym_synset = relation[1]\n",
    "                hypernym_words = words_in_synset(relation[1])\n",
    "#            else:\n",
    "#                hypernym_synset = []\n",
    "#                hypernym_words = []               \n",
    "                hyp_list.append((sense[0],hypernym_synset,hypernym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def hyponyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hyponym\":\n",
    "                hyponym_synset = relation[1]\n",
    "                hyponym_words = words_in_synset(relation[1])\n",
    " #           else:\n",
    " #               hyponym_synset = []\n",
    " #               hyponym_words = []               \n",
    "                hyp_list.append((sense[0],hyponym_synset,hyponym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def meronyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    mero_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"mero_part\":\n",
    "                meronym_synset = relation[1]\n",
    "                meronym_words = words_in_synset(relation[1])\n",
    "                mero_list.append((sense[0],meronym_synset,meronym_words))\n",
    "    return(mero_list)\n",
    "\n",
    "def holonyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    holo_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"holo_part\":\n",
    "                holo_synset = relation[1]\n",
    "                holo_words = words_in_synset(relation[1])\n",
    "                holo_list.append((sense[0],holo_synset,holo_words))\n",
    "    return(holo_list)\n",
    "\n",
    "def antonyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    anto_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"antonym\":\n",
    "                antonym_synset = relation[1]\n",
    "                antonym_words = words_in_synset(relation[1])\n",
    "                anto_list.append((sense[0],antonym_synset,antonym_words))\n",
    "    return(anto_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w9034_13770-v',\n",
       "  'odenet-10390-n',\n",
       "  ['Liegenschaft', 'Grundbesitz', 'Landbesitz']),\n",
       " ('w9034_15292-v', 'odenet-21765-n', ['Schulden', 'Fremdkapital'])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms_word(\"überlassen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w12715_2720-n',\n",
       "  'odenet-14514-n',\n",
       "  ['Saudi-Arabien', 'Königreich Saudi-Arabien', 'Saudisch-Arabien']),\n",
       " ('w12715_2720-n', 'odenet-14519-n', ['Syrien', 'Arabische Republik Syrien']),\n",
       " ('w12715_2720-n', 'odenet-14516-n', ['Türkei', 'Republik Türkei']),\n",
       " ('w12715_9897-n', 'odenet-9309-n', ['Ferner Osten', 'Fernost'])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meronyms_word(\"Morgenland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "übertragen v \n",
      "SENSE: odenet-437-v  ('i32904', 'move from one place to another', [], [('hyponym', 'odenet-2011-v')], ['veräußern', 'übertragen', 'transferieren'])\n",
      "\n",
      "SENSE: odenet-1012-v  ('i30942', 'travel on water propelled by wind or by other means', [], [], ['übertragen', 'navigieren', 'routen', 'übermitteln', 'schicken', 'senden', 'leiten'])\n",
      "\n",
      "SENSE: odenet-9659-v  ('i32904', 'move from one place to another', [], [('hyponym', 'odenet-2011-v'), ('hyponym', 'odenet-10882-v'), ('hyponym', 'odenet-13081-n'), ('hyponym', 'odenet-2065-v'), ('hyponym', 'odenet-26295-n'), ('hyponym', 'odenet-33907-v')], ['übertragen', 'überlassen', 'überantworten', 'abtreten', 'vererben', 'vermachen', 'verleihen', 'überschreiben', 'anheimstellen'])\n",
      "\n",
      "SENSE: odenet-18701-v  ('i22219', 'communicate a disease to', [], [], ['übertragen', 'infizieren', 'anstecken'])\n",
      "\n",
      "SENSE: odenet-20722-v  ('i32904', 'move from one place to another', [], [('hyponym', 'odenet-2011-v')], ['übertragen', 'abgegeben', 'übermittelt'])\n",
      "\n",
      "SENSE: odenet-34404-v  ('i26395', 'restate from one language into another language', [], [('hypernym', 'odenet-25555-a')], ['übertragen', 'übersetzen', 'dolmetschen'])\n",
      "\n",
      "HYPERNYMS: [('w2180_34404-v', 'odenet-25555-a', ['wiederholt', 'mehrfach', 'mehrmalig', 'x-malig', '...malig'])]\n",
      "HYPONYMS: [('w2180_437-v', 'odenet-2011-v', ['laden', 'herunterladen', 'herunterkopieren', 'runterladen', 'downloaden']), ('w2180_9659-v', 'odenet-2011-v', ['laden', 'herunterladen', 'herunterkopieren', 'runterladen', 'downloaden']), ('w2180_9659-v', 'odenet-10882-v', ['übermitteln', 'vermitteln', 'weitergeben', 'tradieren', 'überliefern']), ('w2180_9659-v', 'odenet-13081-n', ['raufladen', 'hochladen', 'online stellen', 'uploaden', 'uppen']), ('w2180_9659-v', 'odenet-2065-v', ['aufgeben', 'übersenden', 'expedieren', 'auf die Post geben', 'abschicken']), ('w2180_9659-v', 'odenet-26295-n', ['Herunterladen', 'Download']), ('w2180_9659-v', 'odenet-33907-v', ['sagen', 'übermitteln', 'mitteilen', 'zur Kenntnis bringen', '(jemanden von etwas) in Kenntnis setzen', '(jemanden über etwas) unterrichten', '(jemanden über etwas) informieren']), ('w2180_20722-v', 'odenet-2011-v', ['laden', 'herunterladen', 'herunterkopieren', 'runterladen', 'downloaden'])]\n",
      "MERONYMS: []\n",
      "HOLONYMS: []\n",
      "ANTONYMS: []\n"
     ]
    }
   ],
   "source": [
    "myword = \"übertragen\"\n",
    "(lemma_id, lemma_value, pos, senses) = check_word_lemma(myword)\n",
    "print (lemma_value + \" \" + pos + \" \")\n",
    "for sense in senses:\n",
    "    print(\"SENSE: \" + str(sense[1]) + \"  \" + str(check_synset(sense[1])) + \"\\n\")\n",
    "print(\"HYPERNYMS: \" + str(hypernyms_word(myword)))\n",
    "print(\"HYPONYMS: \" + str(hyponyms_word(myword)))\n",
    "print(\"MERONYMS: \" + str(meronyms_word(myword)))\n",
    "print(\"HOLONYMS: \" + str(holonyms_word(myword)))\n",
    "print(\"ANTONYMS: \" + str(antonyms_word(myword)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
