{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst müssen einige Module importiert werden, die wir nutzen wollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import random\n",
    "from random import *\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt machen wir die OdeNet-XML-Datei auf, parsen das XML und öffnen eine Datei, in die die Ausgabe geschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_wn = open(r\"C:\\Users\\melaniesiegel\\Documents\\05_Projekte\\WordNet\\OdeNet\\odenet.git\\trunk\\deWordNet.xml\",\"r\",encoding=\"utf-8\")\n",
    "\n",
    "out_lex = open(\"out_lex.txt\",\"w\",encoding=\"utf-8\")\n",
    "\n",
    "tree = ET.parse(de_wn)\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "lexicon = root.find('Lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_lemma greift man auf Lexikon-Einträge zu, bekommt die Lexikon-ID für ein Wort, den Lemma-Wert, POS und die IDs der Synsets, in denen das Wort enthalten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_lemma(word_to_check):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        lemma = lexentry.find('Lemma')\n",
    "        lemma_value = lemma.attrib['writtenForm']\n",
    "        lemma_id = lexentry.attrib['id']\n",
    "        if lemma_value == word_to_check:\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append([sense_id,synset_id])\n",
    "#            print(\"LEMMA: \" + lemma_value + \"\\nPOS: \" + pos + \"\\nSENSE ID: \" + sense_id)\n",
    "            return(lemma_id, lemma_value, pos, senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('w24078', 'Leumund', 'n', [['w24078_5598-n', 'odenet-5598-n']])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_lemma(\"Leumund\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier bekommt man die Lexikon-IDs für eine Liste von Wörtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2ids(wordlist):\n",
    "    word_id_list = []\n",
    "    for word in wordlist:\n",
    "        try:\n",
    "            lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "            word_id_list.append(lemma_id)\n",
    "        except:\n",
    "            print(word + \" NOT IN ODENET\")\n",
    "    return(word_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w14145', 'w44811', 'w1202374', 'w25612']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2ids(['Frühling','Sommer','Herbst','Winter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_id bekommt man für eine Lexikon-ID Lemma, POS, Synsets und Relationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_id(id):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        if lexentry.attrib['id'] == id:\n",
    "            lemma = lexentry.find('Lemma')\n",
    "            lemma_value = lemma.attrib['writtenForm']\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append(synset_id)\n",
    "                relations = []\n",
    "                if sense.find('SenseRelation') != None:\n",
    "                    for relation in sense.iter('SenseRelation'):\n",
    "                        reltype = relation.attrib['relType']\n",
    "                        reltarget = relation.attrib['target']\n",
    "                        relations.append((reltype,reltarget))\n",
    "    return(lemma_value, pos, senses,relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Frühling', 'n', ['odenet-3067-n'], [])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_id('w14145')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit words_in_synset bekommt man die Wörter, die in einem Synset sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_synset(id):\n",
    "    words = []\n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        for sense in lexentry.iter('Sense'):\n",
    "            if sense.attrib['synset'] == id:\n",
    "                lemma = lexentry.find('Lemma').attrib['writtenForm']\n",
    "                words.append(lemma)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gesellschaftssystem', 'Gesellschaftsformation', 'Gesellschaftsform']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_synset('odenet-12371-n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_synset bekommt man alle Informationen zu einem Synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_synset(id):\n",
    "    words = words_in_synset(id)\n",
    "    for synset in lexicon.iter('Synset'):\n",
    "        if id == synset.attrib['id']:\n",
    "            ili = synset.attrib['ili']\n",
    "            try:\n",
    "                en_definition = synset.attrib[\"{http://purl.org/dc/elements/1.1/}description\"]\n",
    "            except KeyError:\n",
    "                en_definition = []\n",
    "            if synset.find('Definition') != None:\n",
    "                de_definition = synset.find('Definition').text.strip()\n",
    "            else:\n",
    "                de_definition = []\n",
    "            relations = []\n",
    "            for relation in synset.iter('SynsetRelation'):\n",
    "                reltype = relation.attrib['relType']\n",
    "                reltarget = relation.attrib['target']\n",
    "                relations.append((reltype,reltarget))\n",
    "            return(ili,en_definition,de_definition, relations, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i10885',\n",
       " 'remote in manner',\n",
       " [],\n",
       " [('antonym', 'odenet-3403-a')],\n",
       " ['distanziert',\n",
       "  'zugeknöpft',\n",
       "  'in sich gekehrt',\n",
       "  'zurückhaltend',\n",
       "  'verschlossen',\n",
       "  'verschwiegen',\n",
       "  'unzugänglich',\n",
       "  'introvertiert',\n",
       "  'nach innen gekehrt',\n",
       "  'unaufgeschlossen',\n",
       "  'nicht mitteilsam',\n",
       "  'reserviert',\n",
       "  'nicht erreichbar'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_synset(\"odenet-10251-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypernyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hypernym\":\n",
    "                hypernym_synset = relation[1]\n",
    "                hypernym_words = words_in_synset(relation[1])\n",
    "#            else:\n",
    "#                hypernym_synset = []\n",
    "#                hypernym_words = []               \n",
    "                hyp_list.append((sense[0],hypernym_synset,hypernym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def hyponyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hyponym\":\n",
    "                hyponym_synset = relation[1]\n",
    "                hyponym_words = words_in_synset(relation[1])\n",
    " #           else:\n",
    " #               hyponym_synset = []\n",
    " #               hyponym_words = []               \n",
    "                hyp_list.append((sense[0],hyponym_synset,hyponym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def meronyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    mero_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"mero_part\":\n",
    "                meronym_synset = relation[1]\n",
    "                meronym_words = words_in_synset(relation[1])\n",
    "                mero_list.append((sense[0],meronym_synset,meronym_words))\n",
    "    return(mero_list)\n",
    "\n",
    "def antonyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    anto_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"antonym\":\n",
    "                antonym_synset = relation[1]\n",
    "                antonym_words = words_in_synset(relation[1])\n",
    "                anto_list.append((sense[0],antonym_synset,antonym_words))\n",
    "    return(anto_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w5185_1043-n',\n",
       "  'odenet-10660-n',\n",
       "  ['Widerstand', 'Gegenwehr', 'Verteidigung', 'Defensive', 'Abwehr'])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms_word(\"Notwehr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w12715_2720-n',\n",
       "  'odenet-14514-n',\n",
       "  ['Saudi-Arabien', 'Königreich Saudi-Arabien', 'Saudisch-Arabien']),\n",
       " ('w12715_2720-n', 'odenet-14519-n', ['Syrien', 'Arabische Republik Syrien']),\n",
       " ('w12715_2720-n', 'odenet-14516-n', ['Türkei', 'Republik Türkei']),\n",
       " ('w12715_9897-n', 'odenet-9309-n', ['Ferner Osten', 'Fernost'])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meronyms_word(\"Morgenland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planung n \n",
      "SENSE: odenet-1763-n  ('i41397', [], 'Ausarbeiten eines Plans', [('hypernym', 'odenet-7966-n')], ['Disposition', 'Planung'])\n",
      "SENSE: odenet-9646-n  ('i70074', 'any of the various versions in the development of a written work', [], [('hypernym', 'odenet-20257-n'), ('hyponym', 'odenet-16223-n')], ['Planung', 'Plan', 'Schema', 'Konzeption', 'Entwurf', 'Vorlage', 'Skizze', 'Zeichnung', 'Layout', 'Grundriss'])\n",
      "HYPERNYMS: [('w8644_1763-n', 'odenet-7966-n', ['Vorbereitung', 'Aufbereitung']), ('w8644_9646-n', 'odenet-20257-n', ['SMSen', '(jemandem eine) SMS schicken', 'antexten', 'simsen', 'SMS verschicken', 'ansimsen'])]\n",
      "HYPONYMS: [('w8644_9646-n', 'odenet-16223-n', ['Explosionszeichnung', 'Explosivdarstellung', 'Explosionsgrafik'])]\n",
      "MERONYMS: []\n",
      "ANTONYMS: []\n"
     ]
    }
   ],
   "source": [
    "myword = \"Planung\"\n",
    "(lemma_id, lemma_value, pos, senses) = check_word_lemma(myword)\n",
    "print (lemma_value + \" \" + pos + \" \")\n",
    "for sense in senses:\n",
    "    print(\"SENSE: \" + str(sense[1]) + \"  \" + str(check_synset(sense[1])))\n",
    "print(\"HYPERNYMS: \" + str(hypernyms_word(myword)))\n",
    "print(\"HYPONYMS: \" + str(hyponyms_word(myword)))\n",
    "print(\"MERONYMS: \" + str(meronyms_word(myword)))\n",
    "print(\"ANTONYMS: \" + str(antonyms_word(myword)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
