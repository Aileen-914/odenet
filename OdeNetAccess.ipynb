{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst müssen einige Module importiert werden, die wir nutzen wollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import random\n",
    "from random import *\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt machen wir die OdeNet-XML-Datei auf, parsen das XML und öffnen eine Datei, in die die Ausgabe geschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_wn = open(r\"C:\\Users\\melaniesiegel\\Documents\\05_Projekte\\WordNet\\OdeNet\\odenet.git\\trunk\\deWordNet.xml\",\"r\",encoding=\"utf-8\")\n",
    "\n",
    "out_lex = open(\"out_lex.txt\",\"w\",encoding=\"utf-8\")\n",
    "\n",
    "tree = ET.parse(de_wn)\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "lexicon = root.find('Lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_lemma greift man auf Lexikon-Einträge zu, bekommt die Lexikon-ID für ein Wort, den Lemma-Wert, POS und die IDs der Synsets, in denen das Wort enthalten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_lemma(word_to_check):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        lemma = lexentry.find('Lemma')\n",
    "        lemma_value = lemma.attrib['writtenForm']\n",
    "        lemma_id = lexentry.attrib['id']\n",
    "        if lemma_value == word_to_check:\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append([sense_id,synset_id])\n",
    "#            print(\"LEMMA: \" + lemma_value + \"\\nPOS: \" + pos + \"\\nSENSE ID: \" + sense_id)\n",
    "            return(lemma_id, lemma_value, pos, senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('w24078', 'Leumund', 'n', [['w24078_5598-n', 'odenet-5598-n']])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_lemma(\"Leumund\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier bekommt man die Lexikon-IDs für eine Liste von Wörtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2ids(wordlist):\n",
    "    word_id_list = []\n",
    "    for word in wordlist:\n",
    "        try:\n",
    "            lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "            word_id_list.append(lemma_id)\n",
    "        except:\n",
    "            print(word + \" NOT IN ODENET\")\n",
    "    return(word_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w14145', 'w44811', 'w1202374', 'w25612']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2ids(['Frühling','Sommer','Herbst','Winter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_id bekommt man für eine Lexikon-ID Lemma, POS, Synsets und Relationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_id(id):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        if lexentry.attrib['id'] == id:\n",
    "            lemma = lexentry.find('Lemma')\n",
    "            lemma_value = lemma.attrib['writtenForm']\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append(synset_id)\n",
    "                relations = []\n",
    "                if sense.find('SenseRelation') != None:\n",
    "                    for relation in sense.iter('SenseRelation'):\n",
    "                        reltype = relation.attrib['relType']\n",
    "                        reltarget = relation.attrib['target']\n",
    "                        relations.append((reltype,reltarget))\n",
    "    return(lemma_value, pos, senses,relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Frühling', 'n', ['odenet-3067-n'], [])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_id('w14145')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit words_in_synset bekommt man die Wörter, die in einem Synset sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_synset(id):\n",
    "    words = []\n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        for sense in lexentry.iter('Sense'):\n",
    "            if sense.attrib['synset'] == id:\n",
    "                lemma = lexentry.find('Lemma').attrib['writtenForm']\n",
    "                words.append(lemma)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gesellschaftssystem', 'Gesellschaftsformation', 'Gesellschaftsform']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_synset('odenet-12371-n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_synset bekommt man alle Informationen zu einem Synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_synset(id):\n",
    "    words = words_in_synset(id)\n",
    "    for synset in lexicon.iter('Synset'):\n",
    "        if id == synset.attrib['id']:\n",
    "            ili = synset.attrib['ili']\n",
    "            try:\n",
    "                en_definition = synset.attrib[\"{http://purl.org/dc/elements/1.1/}description\"]\n",
    "            except KeyError:\n",
    "                en_definition = []\n",
    "            if synset.find('Definition') != None:\n",
    "                de_definition = synset.find('Definition').text.strip()\n",
    "            else:\n",
    "                de_definition = []\n",
    "            relations = []\n",
    "            for relation in synset.iter('SynsetRelation'):\n",
    "                reltype = relation.attrib['relType']\n",
    "                reltarget = relation.attrib['target']\n",
    "                relations.append((reltype,reltarget))\n",
    "            return(ili,en_definition,de_definition, relations, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i81079',\n",
       " [],\n",
       " 'System der Produktion, Verteilung und Konsumierung',\n",
       " [('mero_part', 'odenet-207-n'),\n",
       "  ('mero_part', 'odenet-36097-n'),\n",
       "  ('mero_part', 'odenet-36098-n'),\n",
       "  ('mero_part', 'odenet-36099-n'),\n",
       "  ('mero_part', 'odenet-1959-n')],\n",
       " ['Wirtschaft', 'Volkswirtschaft', 'Ökonomie', 'Wirtschaftsraum'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_synset(\"odenet-565-n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypernyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hypernym\":\n",
    "                hypernym_synset = relation[1]\n",
    "                hypernym_words = words_in_synset(relation[1])\n",
    "#            else:\n",
    "#                hypernym_synset = []\n",
    "#                hypernym_words = []               \n",
    "                hyp_list.append((sense[0],hypernym_synset,hypernym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def hyponyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hyponym\":\n",
    "                hyponym_synset = relation[1]\n",
    "                hyponym_words = words_in_synset(relation[1])\n",
    " #           else:\n",
    " #               hyponym_synset = []\n",
    " #               hyponym_words = []               \n",
    "                hyp_list.append((sense[0],hyponym_synset,hyponym_words))\n",
    "    return(hyp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w5185_1043-n',\n",
       "  'odenet-10660-n',\n",
       "  ['Widerstand', 'Gegenwehr', 'Verteidigung', 'Defensive', 'Abwehr'])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms_word(\"Notwehr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimierung n \n",
      "SENSE: odenet-3630-n  ('i112803', [], 'Verbesserung (oder eine beabsichtigte Verbesserung) in der bestehenden Form oder dem Zustand von Institutionen oder Praktiken', [('hypernym', 'odenet-28861-n')], ['Besserung', 'Läuterung', 'Aufbesserung', 'Verbesserung', 'Optimierung', 'Vervollkommnung', 'Melioration', 'Aufwertung', 'Verfeinerung'])\n",
      "SENSE: odenet-4311-n  ('i54767', 'steering mechanism for a vessel; a mechanical device by which a vessel is steered', [], [('hyponym', 'odenet-664-n'), ('holo_part', 'odenet-9839-n'), ('holo_part', 'odenet-35338-v'), ('holo_part', 'odenet-6844-n')], ['Steuerung', 'Optimierung', 'Angleichung', 'Aussteuerung'])\n",
      "HYPERNYMS: [('w16397_3630-n', 'odenet-28861-n', ['Melioration', 'Meliorisation'])]\n",
      "HYPONYMS: [('w16397_4311-n', 'odenet-664-n', ['Steuerrad', 'Lenker', 'Volant', 'Steuer', 'Lenkrad'])]\n"
     ]
    }
   ],
   "source": [
    "myword = \"Optimierung\"\n",
    "(lemma_id, lemma_value, pos, senses) = check_word_lemma(myword)\n",
    "print (lemma_value + \" \" + pos + \" \")\n",
    "for sense in senses:\n",
    "    print(\"SENSE: \" + str(sense[1]) + \"  \" + str(check_synset(sense[1])))\n",
    "print(\"HYPERNYMS: \" + str(hypernyms_word(myword)))\n",
    "print(\"HYPONYMS: \" + str(hyponyms_word(myword)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
