{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst müssen einige Module importiert werden, die wir nutzen wollen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import random\n",
    "from random import *\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt machen wir die OdeNet-XML-Datei auf, parsen das XML und öffnen eine Datei, in die die Ausgabe geschrieben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_wn = open(r\"C:\\Users\\melaniesiegel\\Documents\\05_Projekte\\WordNet\\OdeNet\\odenet.git\\trunk\\deWordNet.xml\",\"r\",encoding=\"utf-8\")\n",
    "\n",
    "out_lex = open(\"out_lex.txt\",\"w\",encoding=\"utf-8\")\n",
    "\n",
    "tree = ET.parse(de_wn)\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "lexicon = root.find('Lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_lemma greift man auf Lexikon-Einträge zu, bekommt die Lexikon-ID für ein Wort, den Lemma-Wert, POS und die IDs der Synsets, in denen das Wort enthalten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_lemma(word_to_check):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        lemma = lexentry.find('Lemma')\n",
    "        lemma_value = lemma.attrib['writtenForm']\n",
    "        lemma_id = lexentry.attrib['id']\n",
    "        if lemma_value == word_to_check:\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append([sense_id,synset_id])\n",
    "#            print(\"LEMMA: \" + lemma_value + \"\\nPOS: \" + pos + \"\\nSENSE ID: \" + sense_id)\n",
    "            return(lemma_id, lemma_value, pos, senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('w24078', 'Leumund', 'n', [['w24078_5598-n', 'odenet-5598-n']])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_lemma(\"Leumund\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier bekommt man die Lexikon-IDs für eine Liste von Wörtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2ids(wordlist):\n",
    "    word_id_list = []\n",
    "    for word in wordlist:\n",
    "        try:\n",
    "            lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "            word_id_list.append(lemma_id)\n",
    "        except:\n",
    "            print(word + \" NOT IN ODENET\")\n",
    "    return(word_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w14145', 'w44811', 'w1202374', 'w25612']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2ids(['Frühling','Sommer','Herbst','Winter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_word_id bekommt man für eine Lexikon-ID Lemma, POS, Synsets und Relationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_id(id):    \n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        if lexentry.attrib['id'] == id:\n",
    "            lemma = lexentry.find('Lemma')\n",
    "            lemma_value = lemma.attrib['writtenForm']\n",
    "            pos = lemma.attrib['partOfSpeech']\n",
    "            senses = []\n",
    "            for sense in lexentry.iter('Sense'):\n",
    "                sense_id = sense.attrib['id']\n",
    "                synset_id = sense.attrib['synset']\n",
    "#                senserelation_type = lexentry.find('SenseRelation').attrib['relType']\n",
    "#                senserelation_target = lexentry.find('SenseRelation').attrib['target']\n",
    "                senses.append(synset_id)\n",
    "                relations = []\n",
    "                if sense.find('SenseRelation') != None:\n",
    "                    for relation in sense.iter('SenseRelation'):\n",
    "                        reltype = relation.attrib['relType']\n",
    "                        reltarget = relation.attrib['target']\n",
    "                        relations.append((reltype,reltarget))\n",
    "    return(lemma_value, pos, senses,relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Frühling', 'n', ['odenet-3067-n'], [])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_id('w14145')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit words_in_synset bekommt man die Wörter, die in einem Synset sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_synset(id):\n",
    "    words = []\n",
    "    for lexentry in lexicon.iter('LexicalEntry'):\n",
    "        for sense in lexentry.iter('Sense'):\n",
    "            if sense.attrib['synset'] == id:\n",
    "                lemma = lexentry.find('Lemma').attrib['writtenForm']\n",
    "                words.append(lemma)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gesellschaftssystem', 'Gesellschaftsformation', 'Gesellschaftsform']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_synset('odenet-12371-n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit check_synset bekommt man alle Informationen zu einem Synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_synset(id):\n",
    "    words = words_in_synset(id)\n",
    "    for synset in lexicon.iter('Synset'):\n",
    "        if id == synset.attrib['id']:\n",
    "            ili = synset.attrib['ili']\n",
    "            try:\n",
    "                en_definition = synset.attrib[\"{http://purl.org/dc/elements/1.1/}description\"]\n",
    "            except KeyError:\n",
    "                en_definition = []\n",
    "            if synset.find('Definition') != None:\n",
    "                de_definition = synset.find('Definition').text.strip()\n",
    "            else:\n",
    "                de_definition = []\n",
    "            relations = []\n",
    "            for relation in synset.iter('SynsetRelation'):\n",
    "                reltype = relation.attrib['relType']\n",
    "                reltarget = relation.attrib['target']\n",
    "                relations.append((reltype,reltarget))\n",
    "            return(ili,en_definition,de_definition, relations, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', [], [], [], ['Kaskoversicherung', 'Fahrzeugversicherung'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_synset(\"odenet-16281-n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypernyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hypernym\":\n",
    "                hypernym_synset = relation[1]\n",
    "                hypernym_words = words_in_synset(relation[1])\n",
    "#            else:\n",
    "#                hypernym_synset = []\n",
    "#                hypernym_words = []               \n",
    "                hyp_list.append((sense[0],hypernym_synset,hypernym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def hyponyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    hyp_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"hyponym\":\n",
    "                hyponym_synset = relation[1]\n",
    "                hyponym_words = words_in_synset(relation[1])\n",
    " #           else:\n",
    " #               hyponym_synset = []\n",
    " #               hyponym_words = []               \n",
    "                hyp_list.append((sense[0],hyponym_synset,hyponym_words))\n",
    "    return(hyp_list)\n",
    "\n",
    "def meronyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    mero_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"mero_part\":\n",
    "                meronym_synset = relation[1]\n",
    "                meronym_words = words_in_synset(relation[1])\n",
    "                mero_list.append((sense[0],meronym_synset,meronym_words))\n",
    "    return(mero_list)\n",
    "\n",
    "def antonyms_word(word):\n",
    "    lemma_id, lemma, pos, senses = check_word_lemma(word)\n",
    "    anto_list = []\n",
    "    for sense in senses:\n",
    "        (ili,definition,de_definition, relations, words) = check_synset(sense[1])\n",
    "        for relation in relations:\n",
    "            if relation[0] == \"antonym\":\n",
    "                antonym_synset = relation[1]\n",
    "                antonym_words = words_in_synset(relation[1])\n",
    "                anto_list.append((sense[0],antonym_synset,antonym_words))\n",
    "    return(anto_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w39983_9969-n', 'odenet-11456-n', ['Verkehr', 'Verkehrswesen'])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernyms_word(\"Fahrzeug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w12715_2720-n',\n",
       "  'odenet-14514-n',\n",
       "  ['Saudi-Arabien', 'Königreich Saudi-Arabien', 'Saudisch-Arabien']),\n",
       " ('w12715_2720-n', 'odenet-14519-n', ['Syrien', 'Arabische Republik Syrien']),\n",
       " ('w12715_2720-n', 'odenet-14516-n', ['Türkei', 'Republik Türkei']),\n",
       " ('w12715_9897-n', 'odenet-9309-n', ['Ferner Osten', 'Fernost'])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meronyms_word(\"Morgenland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ausverkauft a \n",
      "SENSE: odenet-10000-a  ('', [], 'es gibt (für eine Veranstaltung z.B.) keine Eintrittskarten mehr', [('antonym', 'odenet-9205-a'), ('hypernym', 'odenet-8986-n')], ['voll', 'besetzt', 'belegt', 'ausverkauft'])\n",
      "\n",
      "HYPERNYMS: [('w40118_10000-a', 'odenet-8986-n', ['Lage', 'Zustand', 'Konstellation', 'Umstand', 'Sachverhalt', 'Fall', 'Status', 'Kontext', 'Gegebenheit', 'Situation', 'Stand der Dinge'])]\n",
      "HYPONYMS: []\n",
      "MERONYMS: []\n",
      "ANTONYMS: [('w40118_10000-a', 'odenet-9205-a', ['offen', 'frei', 'vakant', 'nicht besetzt', 'ausgeschrieben', 'unbesetzt', 'in der Ausschreibung', 'zu besetzen'])]\n"
     ]
    }
   ],
   "source": [
    "myword = \"ausverkauft\"\n",
    "(lemma_id, lemma_value, pos, senses) = check_word_lemma(myword)\n",
    "print (lemma_value + \" \" + pos + \" \")\n",
    "for sense in senses:\n",
    "    print(\"SENSE: \" + str(sense[1]) + \"  \" + str(check_synset(sense[1])) + \"\\n\")\n",
    "print(\"HYPERNYMS: \" + str(hypernyms_word(myword)))\n",
    "print(\"HYPONYMS: \" + str(hyponyms_word(myword)))\n",
    "print(\"MERONYMS: \" + str(meronyms_word(myword)))\n",
    "print(\"ANTONYMS: \" + str(antonyms_word(myword)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
